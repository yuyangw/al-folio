---
---

@string{acs = {Americam Chemical Society,}}

@article{wang2023denoise,
  abbr={2023denoise},
  title={Denoise Pre-training on Non-equilibrium Molecules for Accurate and Transferable Neural Potentials},
  author={<b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Xu, Changwen and Li, Zijie and Barati Farimani, Amir},
  journal={arXiv preprint},
  year={2023},
  arxiv={2303.02216},
  pdf={https://arxiv.org/pdf/2303.02216.pdf},
  code={https://github.com/yuyangw/Denoise-Pretrain-ML-Potential}, 
  abstract={Machine learning methods, particularly recent advances in equivariant graph neural networks (GNNs), have been investigated as surrogate models to expensive ab initio quantum mechanics (QM) approaches for molecular potential predictions. However, building accurate and transferable potential models using GNNs remains challenging, as the quality and quantity of data are greatly limited by QM calculations, especially for large and complex molecular systems. In this work, we propose denoise pre-training on non-equilibrium molecular conformations to achieve more accurate and transferable GNN potential predictions. Specifically, GNNs are pre-trained by predicting the random noises added to atomic coordinates of sampled non-equilibrium conformations. Rigorous experiments on multiple benchmarks reveal that pre-training significantly improves the accuracy of neural potentials. Furthermore, we show that the proposed pre-training approach is model-agnostic, as it improves the performance of different invariant and equivariant GNNs. Notably, our models pre-trained on small molecules demonstrate remarkable transferability, improving performance when fine-tuned on diverse molecular systems, including different elements, charged molecules, biomolecules, and larger systems. These results highlight the potential for leveraging denoise pre-training approaches to build more generalizable neural potentials for complex molecular systems.}
}

@article{cao2023neural,
  abbr={2023neural},
  title={Neural Network Predicts Ion Concentration Profiles under Nanoconfinement},
  author={Cao, Zhonglin and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Lorsung, Cooper and Barati Farimani, Amir},
  journal={arXiv preprint},
  year={2023},
  arxiv={2304.04896},
  pdf={https://arxiv.org/pdf/2304.04896.pdf},
  code={https://github.com/zcao0420/IonNet},
  abstract={Modeling the ion concentration profile in nanochannel plays an important role in understanding the electrical double layer and electroosmotic flow. Due to the non-negligible surface interaction and the effect of discrete solvent molecules, molecular dynamics (MD) simulation is often used as an essential tool to study the behavior of ions under nanoconfinement. Despite the accuracy of MD simulation in modeling nanoconfinement systems, it is computationally expensive. In this work, we propose neural network to predict ion concentration profiles in nanochannels with different configurations, including channel widths, ion molarity, and ion types. By modeling the ion concentration profile as a probability distribution, our neural network can serve as a much faster surrogate model for MD simulation with high accuracy. We further demonstrate the superior prediction accuracy of neural network over XGBoost. Lastly, we demonstrated that neural network is flexible in predicting ion concentration profiles with different bin sizes. Overall, our deep learning model is a fast, flexible, and accurate surrogate model to predict ion concentration profiles in nanoconfinement.}
}

@article{xu2023transpolymer,
  abbr={2023transpolymer},
  title={TransPolymer: a Transformer-based Language Model for Polymer Property Predictions},
  author={Xu, Changwen and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Barati Farimani, Amir},
  journal={npj Computational Materials},
  year={2023},
  html={https://www.nature.com/articles/s41524-023-01016-5},
  arxiv={2209.01307},
  pdf={https://www.nature.com/articles/s41524-023-01016-5.pdf}, 
  code={https://github.com/ChangwenXu98/TransPolymer},
  abstract={Accurate and efficient prediction of polymer properties is of great significance in polymer design. Conventionally, expensive and time-consuming experiments or simulations are required to evaluate polymer functions. Recently, Transformer models, equipped with self-attention mechanisms, have exhibited superior performance in natural language processing. However, such methods have not been investigated in polymer sciences. Herein, we report TransPolymer, a Transformer-based language model for polymer property prediction. Our proposed polymer tokenizer with chemical awareness enables learning representations from polymer sequences. Rigorous experiments on ten polymer property prediction benchmarks demonstrate the superior performance of TransPolymer. Moreover, we show that TransPolymer benefits from pretraining on large unlabeled dataset via Masked Language Modeling. Experimental results further manifest the important role of self-attention in modeling polymer sequences. We highlight this model as a promising computational tool for promoting rational polymer design and understanding structure-property relationships from a data science view.}
}

@article{cao2023moformer,
  abbr={2023moformer},
  author = {Cao, Zhonglin and Magar, Rishikesh and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Barati Farimani, Amir},
  title = {MOFormer: Self-Supervised Transformer Model for Metal-Organic Framework Property Prediction},
  journal = {Journal of the American Chemical Society},
  volume = {145},
  number = {5},
  pages = {2958-2967},
  year = {2023},
  doi = {10.1021/jacs.2c11420},
  html={https://pubs.acs.org/doi/10.1021/jacs.2c11420},
  arxiv={2210.14188},
  pdf={https://pubs.acs.org/doi/pdf/10.1021/jacs.2c11420},
  code={https://github.com/zcao0420/MOFormer},    
  abstract = {Metalâ€“organic frameworks (MOFs) are materials with a high degree of porosity that can be used for many applications. However, the chemical space of MOFs is enormous due to the large variety of possible combinations of building blocks and topology. Discovering the optimal MOFs for specific applications requires an efficient and accurate search over countless potential candidates. Previous high-throughput screening methods using computational simulations like DFT can be time-consuming. Such methods also require the 3D atomic structures of MOFs, which adds one extra step when evaluating hypothetical MOFs. In this work, we propose a structure-agnostic deep learning method based on the Transformer model, named as MOFormer, for property predictions of MOFs. MOFormer takes a text string representation of MOF (MOFid) as input, thus circumventing the need of obtaining the 3D structure of a hypothetical MOF and accelerating the screening process. By comparing to other descriptors such as Stoichiometric-120 and revised autocorrelations, we demonstrate that MOFormer can achieve state-of-the-art structure-agnostic prediction accuracy on all benchmarks. Furthermore, we introduce a self-supervised learning framework that pretrains the MOFormer via maximizing the cross-correlation between its structure-agnostic representations and structure-based representations of the crystal graph convolutional neural network (CGCNN) on >400k publicly available MOF data. Benchmarks show that pretraining improves the prediction accuracy of both models on various downstream prediction tasks. Furthermore, we revealed that MOFormer can be more data-efficient on quantum-chemical property prediction than structure-based CGCNN when training data is limited. Overall, MOFormer provides a novel perspective on efficient MOF property prediction using deep learning.}
}

@article{jian2022predicting,
  abbr={2022IL},
  title={Predicting CO<sub>2</sub> Absorption in Ionic Liquids with Molecular Descriptors and Explainable Graph Neural Networks},
  author={Jian, Yue and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Barati Farimani, Amir},
  journal={ACS Sustainable Chemistry & Engineering},
  year={2022},
  html={https://pubs.acs.org/doi/full/10.1021/acssuschemeng.2c05985},
  arxiv={https://arxiv.org/abs/2210.01120},
  pdf={https://arxiv.org/pdf/2210.01120.pdf},
  code={https://github.com/ftyuejian/Predicting-CO2-Absorption-in-Ionic-Liquid-with-Molecular-Descriptors-and-Explainable-GNN},
  abstract={Ionic Liquids (ILs) provide a promising solution for CO2 capture and storage to mitigate global warming. However, identifying and designing the high-capacity IL from the giant chemical space requires expensive, and exhaustive simulations and experiments. Machine learning (ML) can accelerate the process of searching for desirable ionic molecules through accurate and efficient property predictions in a data-driven manner. But existing descriptors and ML models for the ionic molecule suffer from the inefficient adaptation of molecular graph structure. Besides, few works have investigated the explainability of ML models to help understand the learned features that can guide the design of efficient ionic molecules. In this work, we develop both fingerprint-based ML models and Graph Neural Networks (GNNs) to predict the CO2 absorption in ILs. Fingerprint works on graph structure at the feature extraction stage, while GNNs directly handle molecule structure in both the feature extraction and model prediction stage. We show that our method outperforms previous ML models by reaching a high accuracy (MAE of 0.0137, R2 of 0.9884). Furthermore, we take the advantage of GNNs feature representation and develop a substructure-based explanation method that provides insight into how each chemical fragments within IL molecules contribute to the CO2 absorption prediction of ML models. We also show that our explanation result agrees with some ground truth from the theoretical reaction mechanism of CO2 absorption in ILs, which can advise on the design of novel and efficient functional ILs in the future.}
}

@article{magar2022crystal,
  abbr={2022crystaltwins},
  title={Crystal Twins: Self-supervised Learning for Crystalline Material Property Prediction},
  author={Magar, Rishikesh and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Barati Farimani, Amir},
  journal={npj Computational Materials},
  year={2022},
  html={https://www.nature.com/articles/s41524-022-00921-5},
  arxiv={2205.01893},
  pdf={https://arxiv.org/pdf/2205.01893.pdf},
  code={https://github.com/RishikeshMagar/Crystal-Twins},
  abstract={Machine learning (ML) models have been widely successful in the prediction of material properties. However, large labeled datasets required for training accurate ML models are elusive and computationally expensive to generate. Recent advances in Self-Supervised Learning (SSL) frameworks capable of training ML models on unlabeled data have mitigated this problem and demonstrated superior performance in computer vision and natural language processing tasks. Drawing inspiration from the developments in SSL, we introduce Crystal Twins (CT): an SSL method for crystalline materials property prediction. Using a large unlabeled dataset, we pre-train a Graph Neural Network (GNN) by applying the redundancy reduction principle to the graph latent embeddings of augmented instances obtained from the same crystalline system. By sharing the pre-trained weights when fine-tuning the GNN for regression tasks, we significantly improve the performance for 7 challenging material property prediction benchmarks.}
  }

@article{wang2022GNN,
  abbr={2022GNN},
  title={Graph Neural Networks for Molecules},
  author={<b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Li, Zijie and Barati Farimani, Amir},
  journal={A chapter for book "Machine Learning in Molecular Sciences" (Editor: Dr. Jerzy Leszczynski) to be published by Springer Nature},
  year={2022},
  arxiv={2209.05582},
  pdf={https://arxiv.org/pdf/2209.05582.pdf},
  abstract={Graph neural networks (GNNs), which are capable of learning representations from graphical data, are naturally suitable for modeling molecular systems. This review introduces GNNs and their various applications for small organic molecules. GNNs rely on message-passing operations, a generic yet powerful framework, to update node features iteratively. Many researches design GNN architectures to effectively learn topological information of 2D molecule graphs as well as geometric information of 3D molecular systems. GNNs have been implemented in a wide variety of molecular applications, including molecular property prediction, molecular scoring and docking, molecular optimization and de novo generation, molecular dynamics simulation, etc. Besides, the review also summarizes the recent development of self-supervised learning for molecules with GNNs.}
}

@article{wang2022improving,
  abbr={2022imolclr},
  title={Improving Molecular Contrastive Learning via Faulty Negative Mitigation and Decomposed Fragment Contrast},
  author={<b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Magar, Rishikesh and Liang, Chen and Barati Farimani, Amir},
  journal={Journal of Chemical Information and Modeling},
  year={2022},
  html={https://pubs.acs.org/doi/full/10.1021/acs.jcim.2c00495},
  arxiv={2202.09346},
  pdf={https://arxiv.org/pdf/2202.09346.pdf},
  code={https://github.com/yuyangw/iMolCLR},
  abstract={Deep learning has been a prevalence in computational chemistry and widely implemented in molecule property predictions. Recently, self-supervised learning (SSL), especially contrastive learning (CL), gathers growing attention for the potential to learn molecular representations that generalize to the gigantic chemical space. Unlike supervised learning, SSL can directly leverage large unlabeled data, which greatly reduces the effort to acquire molecular property labels through costly and time-consuming simulations or experiments. However, most molecular SSL methods borrow the insights from the machine learning community but neglect the unique cheminformatics (e.g., molecular fingerprints) and multi-level graphical structures (e.g., functional groups) of molecules. In this work, we propose iMolCLR: improvement of Molecular Contrastive Learning of Representations with graph neural networks (GNNs) in two aspects, (1) mitigating faulty negative contrastive instances via considering cheminformatics similarities between molecule pairs; (2) fragment-level contrasting between intra- and inter-molecule substructures decomposed from molecules. Experiments have shown that the proposed strategies significantly improve the performance of GNN models on various challenging molecular property predictions. In comparison to the previous CL framework, iMolCLR demonstrates an averaged 1.2% improvement of ROC-AUC on 8 classification benchmarks and an averaged 10.1% decrease of the error on 6 regression benchmarks. On most benchmarks, the generic GNN pre-trained by iMolCLR rivals or even surpasses supervised learning models with sophisticated architecture designs and engineered features. Further investigations demonstrate that representations learned through iMolCLR intrinsically embed scaffolds and functional groups that can reason molecule similarities.}
}

@article{wang2022molclr,
  abbr={2022molclr},
  title={Molecular Contrastive Learning of Representations via Graph Neural Networks},
  author={<b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Wang, Jianren and Cao, Zhonglin and Barati Farimani, Amir},
  journal={Nature Machine Intelligence},
  year={2022},
  html={https://www.nature.com/articles/s42256-022-00447-x},
  arxiv={2102.10056},
  pdf={https://www.nature.com/articles/s42256-022-00447-x.pdf},
  code={https://github.com/yuyangw/MolCLR},
  media={https://techxplore.com/news/2022-03-machine-smarter-drug-discovery.html},
  selected={true},
  abstract={Molecular machine learning bears promise for efficient molecular property prediction and drug discovery. However, labelled molecule data can be expensive and time consuming to acquire. Due to the limited labelled data, it is a great challenge for supervised-learning machine learning models to generalize to the giant chemical space. Here we present MolCLR (Molecular Contrastive Learning of Representations via Graph Neural Networks), a self-supervised learning framework that leverages large unlabelled data (~10 million unique molecules). In MolCLR pre-training, we build molecule graphs and develop graph-neural-network encoders to learn differentiable representations. Three molecule graph augmentations are proposed: atom masking, bond deletion and subgraph removal. A contrastive estimator maximizes the agreement of augmentations from the same molecule while minimizing the agreement of different molecules. Experiments show that our contrastive learning framework significantly improves the performance of graph-neural-network encoders on various molecular property benchmarks including both classification and regression tasks. Benefiting from pre-training on the large unlabelled database, MolCLR even achieves state of the art on several challenging benchmarks after fine-tuning. In addition, further investigations demonstrate that MolCLR learns to embed molecules into representations that can distinguish chemically reasonable molecular similarities.}
}

@article{yadav2022prediction,
  abbr={2022gpcr},
  title={Prediction of GPCR activity using Deep Learning},
  author={Yadav, Prakarsh and Mollaei, Parisa and Cao, Zhonglin and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Barati Farimani, Amir},
  journal={Computational and Structural Biotechnology Journal},
  year={2022},
  html={https://www.sciencedirect.com/science/article/pii/S2001037022001726?via%3Dihub},
  pdf={Prediction_of_GPCR_activity_using_Deep_Learning.pdf},
  abstract={GPCRs are the target for one-third of the FDA-approved drugs, however; the development of new drug molecules targeting GPCRs is limited by the lack of mechanistic understanding of the GPCR structure-activity-function relationship. To modulate the GPCR activity with highly specific drugs and minimal side-effects, it is necessary to quantitatively describe the important structural features in the GPCR and correlate them to the activation state of GPCR. In this study, we developed 3 ML approaches to predict the conformation state of GPCR proteins. Additionally, we predict the activity level of GPCRs based on their structure. We leverage the unique advantages of each of the 3 ML approach, interpretability of XGBoost, minimal feature engineering for 3D convolutional neural network, and graph representation of protein structure for graph neural network. By using these ML approaches, we are able to predict the GPCRs activation state with high accuracy (91\%-95\%) and also predict the activation state of GPCRs with low error (MAE of 7.15-10.58). Furthermore, the interpretation of the ML approaches allow us to determine the importance of each of the features in distinguishing between the GPCRs conformations.}
}

@article{magar2021auglichem,
  abbr={2021auglichem},
  title={AugLiChem: Data Augmentation Library of Chemical Structures for Machine Learning},
  author={Magar*, Rishikesh and <b><i>Wang*</i></b>, <b><i>Yuyang</i></b> and Lorsung*, Cooper and Liang, Chen and Ramasubramanian, Hariharan and Li, Peiyuan and Barati Farimani, Amir},
  journal={Machine Learning: Science and Technology},
  year={2022},
  arxiv={2111.15112},
  html={https://iopscience.iop.org/article/10.1088/2632-2153/ac9c84},
  pdf={https://arxiv.org/pdf/2111.15112.pdf},
  code={https://github.com/BaratiLab/AugLiChem},
  abstract={Machine learning (ML) has demonstrated the promise for accurate and efficient property prediction of molecules and crystalline materials. To develop highly accurate ML models for chemical structure property prediction, datasets with sufficient samples are required. However, obtaining clean and sufficient data of chemical properties can be expensive and time-consuming, which greatly limits the performance of ML models. Inspired by the success of data augmentations in computer vision and natural language processing, we developed AugLiChem: the data augmentation library for chemical structures. Augmentation methods for both crystalline systems and molecules are introduced, which can be utilized for fingerprint-based ML models and Graph Neural Networks (GNNs). We  show that using our augmentation strategies significantly improves the performance of ML models, especially when using GNNs. In addition, the augmentations that we developed can be used as a direct plug-in module during training and have demonstrated the effectiveness when implemented with different GNN models through the AugliChem library. The Python-based package for our implementation of Auglichem: Data augmentation library for chemical structures, is publicly available at: https://github.com/BaratiLab/AugLiChem.}
}

@article{yoon2021deep,
  abbr={2021catgym},
  title={Deep Reinforcement Learning for Predicting Kinetic Pathways to Surface Reconstruction in a Ternary Alloy.},
  author={Yoon, Junwoong and Cao, Zhonglin and Raju, Rajesh and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Burnley, Robert and Gellman, Andrew J and Barati Farimani, Amir and Ulissi, Zachary W},
  journal={Machine Learning: Science and Technology},
  year={2021},
  publisher={IOP Publishing},
  code={https://github.com/ulissigroup/catgym},
  html={https://iopscience.iop.org/article/10.1088/2632-2153/ac191c},
  pdf={https://iopscience.iop.org/article/10.1088/2632-2153/ac191c/pdf},
  media={https://www.marktechpost.com/2021/10/03/cmu-researchers-introduce-catgym-a-deep-reinforcement-learning-drl-environment-for-predicting-kinetic-pathways-to-surface-reconstruction-in-a-ternary-alloy/},
  abstract={The majority of computational catalyst design focuses on the screening of material components and alloy composition to optimize selectivity and activity for a given reaction. However, predicting the metastability of the alloy catalyst surface at realistic operating conditions requires an extensive sampling of possible surface reconstructions and their associated kinetic pathways. We present CatGym, a deep reinforcement learning (DRL) environment for predicting the thermal surface reconstruction pathways and their associated kinetic barriers in crystalline solids under reaction conditions. The DRL agent iteratively changes the positions of atoms in the near-surface region to generate kinetic pathways to accessible local minima involving changes in the surface compositions. We showcase our agent by predicting the surface reconstruction pathways of a ternary Ni3Pd3Au2(111) alloy catalyst. Our results show that the DRL agent can not only explore more diverse surface compositions than the conventional minima hopping method, but also generate the kinetic surface reconstruction pathways. We further demonstrate that the kinetic pathway to a global minimum energy surface composition and its associated transition state predicted by our agent is in good agreement with the minimum energy path predicted by nudged elastic band calculations.}
}

@article{wang2021efficient,
  abbr={2021grapheneRL},
  title={Efficient Water Desalination with Graphene Nanopores Obtained using Artificial Intelligence},
  author={<b><i>Wang*</i></b>, <b><i>Yuyang</i></b> and Cao*, Zhonglin and Barati Farimani, Amir},
  journal={npj 2D Materials and Applications},
  volume={5},
  number={1},
  pages={1--9},
  year={2021},
  publisher={Nature Publishing Group},
  code={https://github.com/BaratiLab/Graphene-RL},
  html={https://www.nature.com/articles/s41699-021-00246-9},
  arxiv={2101.07399},
  pdf={https://www.nature.com/articles/s41699-021-00246-9.pdf},
  media={https://engineering.cmu.edu/news-events/news/2021/10/20-ai-desalination.html},
  abstract={Two-dimensional nanomaterials, such as graphene, have been extensively studied because of their outstanding physical properties. Structure and topology of nanopores on such materials can be important for their performances in real-world engineering applications, like water desalination. However, discovering the most efficient nanopores often involves a very large number of experiments or simulations that are expensive and time-consuming. In this work, we propose a data-driven artificial intelligence (AI) framework for discovering the most efficient graphene nanopore for water desalination. Via a combination of deep reinforcement learning (DRL) and convolutional neural network (CNN), we are able to rapidly create and screen thousands of graphene nanopores and select the most energy-efficient ones. Molecular dynamics (MD) simulations on promising AI-created graphene nanopores show that they have higher water flux while maintaining rival ion rejection rate compared to the normal circular nanopores. Irregular shape with rough edges geometry of AI-created pores is found to be the key factor for their high water desalination performance. Ultimately, this study shows that AI can be a powerful tool for nanomaterial design and screening.}
}

@inproceedings{wang2021aril,
  abbr={2021aril},
  title={Adversarially Robust Imitation Learning},
  author={Wang, Jianren and Zhuang, Ziwen and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Zhao, Hang},
  booktitle={5th Annual Conference on Robot Learning},
  year={2021},
  html={https://openreview.net/forum?id=9aVCUv3nKBg},
  pdf={https://openreview.net/pdf?id=9aVCUv3nKBg},
  abstract={Modern imitation learning (IL) utilizes deep neural networks (DNNs) as function approximators to mimic the policy of the expert demonstrations. However, DNNs can be easily fooled by subtle noise added to the input, which is even non-detectable by humans. This makes the learned agent vulnerable to attacks, especially in IL where agents can struggle to recover from the errors. In such light, we propose a sound Adversarially Robust Imitation Learning (ARIL) method. In our setting, an agent and an adversary are trained alternatively. The former with adversarially attacked input at each timestep mimics the behavior of an online expert and the latter learns to add perturbations on the states by forcing the learned agent to fail on choosing the right decisions. We theoretically prove that ARIL can achieve adversarial robustness and evaluate ARIL on multiple benchmarks from DM Control Suite. The result reveals that our method (ARIL) achieves better robustness compare with other imitation learning methods under both sensory attack and physical attack.}
}

@article{wang2020bio,
  abbr={2020peptidegan},
  title={Bio-informed Protein Sequence Generation for Multi-class Virus Mutation Prediction},
  author={<b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Yadav, Prakarsh and Magar, Rishikesh and Barati Farimani, Amir},
  journal={bioRxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory},
  biorxiv={https://www.biorxiv.org/content/10.1101/2020.06.11.146167v1.abstract},
  pdf={https://www.biorxiv.org/content/biorxiv/early/2020/06/12/2020.06.11.146167.full.pdf},
  abstract={Viral pandemics are emerging as a serious global threat to public health, like the recent outbreak of COVID-19. Viruses, especially those belonging to a large family of +ssRNA viruses, have a high possibility of mutating by inserting, deleting, or substituting one or multiple genome segments. It is of great importance for human health worldwide to predict the possible virus mutations, which can effectively avoid the potential second outbreak. In this work, we develop a GAN-based multi-class protein sequence generative model, named ProteinSeqGAN. Given the viral species, the generator is modeled on RNNs to predict the corresponding antigen epitope sequences synthesized by viral genomes. Additionally, a Graphical Protein Autoencoder (GProAE) built upon VAE is proposed to featurize proteins bioinformatically. GProAE, as a multi-class discriminator, also learns to evaluate the goodness of protein sequences and predict the corresponding viral species. Further experiments show that our ProteinSeqGAN model can generate valid antigen protein sequences from both bioinformatics and statistics perspectives, which can be promising predictions of virus mutations.}
}

@article{mullicklearning,
  abbr={2020emsr},
  title={Learning Super-Resolution Electron Density Map of Proteins using 3D U-Net},
  author={Mullick, Baishali and <b><i>Wang</i></b>, <b><i>Yuyang</i></b> and Yadav, Prakarsh and Barati Farimani, Amir},
  year={2020},
  journal={Machine Learning for Structural Biology Workshop at NeurIPS},
  pdf={https://www.mlsb.io/papers/MLSB2020_Learning_Super-Resolution_Electron_Density.pdf},
  abstract={A well-established protein structure is essential for understanding protein molecular mechanism, phenotypic implication and drug discovery. Recent development of cryo-Electron Microscopy (cryo-EM) offers the advantage of easy sample preparation and not requiring crystallized protein for structural biology. However, the resolution of cryo-EM electron density maps used to determine protein structure, is not at par with X-ray diffraction (XRD) or NMR. In this work, we propose to leverage a deep learning-based model to increase the resolution of low-quality electron density maps. The model is built upon U-Net with 3D convolutional layers, which contains three components: encoder, bottleneck, and decoder. To get paired maps of different resolutions, we collect high-resolution maps from XRD as ground truth labels. While the low-resolution maps are obtained through a noise model which combines dilation operations, Gaussian filters and Gaussian noise. We also introduce data augmentation techniques during model training, like random cropping, rotation, and flipping. Experiments show that when applied to low-resolution electron maps, the U-Net model can improve the resolution in the metric of EMRinger score, which redesigns the map so that it resolves the regions of ambiguity to offer greater certainty in the position of amino acids. }
}